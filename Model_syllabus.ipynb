{"cells":[{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1670595183644,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"QAp7XMeLnIDZ","outputId":"df05de45-006f-431e-817b-fba5201eb293"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","from torch.utils.data import DataLoader\n","\n","# device check\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":720,"status":"ok","timestamp":1670595184893,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"9H2ScqzCLdtl","outputId":"12b04935-4706-476e-f61f-f87c53de0b9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","8200\n"]}],"source":["print(torch.backends.cudnn.is_available())\n","print(torch.backends.cudnn.version())"]},{"cell_type":"markdown","metadata":{"id":"q3Xp5rqonX4H"},"source":["# Fetching data\n","\n","Read the data as the Pandas Dataframe"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1670595184894,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"O1R7auk9nZ8I","outputId":"dc74e7b6-758d-4a81-bc1d-959844c9e4fb"},"outputs":[{"data":{"text/plain":["125912"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["# I use Pandas library to read the data from CSV and drop all the NA value.'''\n","df = pd.read_csv('converted_syllable_dict.csv')\n","df.dropna(inplace = True)\n","# df = df.head(500)\n","\n","# Split the data into the list of word string and the list of their syllbus\n","word = list(df['word'])\n","word = [each_word.lower() for each_word in word]\n","sylla_count = list(df['syllable_count'])\n","len(df)\n","\n","# print(word)\n","# print(sylla_count)"]},{"cell_type":"markdown","metadata":{"id":"ORs1DhN6u0Ib"},"source":["# Pre-process data\n","\n","Create a look up table and reformat the data"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670595184894,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"zVYyMYRHr-0B","outputId":"29c91083-b0bf-43bb-9bdc-2bd7ece97c48"},"outputs":[{"data":{"text/plain":["28"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["# Convert all word to the same lenght for embedding purpose\n","max_len = 0\n","for i in word:\n","    if len(i) > max_len:\n","        max_len = len(i)\n","\n","max_len"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670595184894,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"OhDYJp3SsL3k"},"outputs":[],"source":["# Add \" \" to the end of each word so all word in the corpus has the same length\n","word = list(map(lambda x: x + \" \" * (max_len - len(x)), word ))"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670595184894,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"JYS24ibxuFFp"},"outputs":[],"source":["# Create the look up table with all characters in the corpus\n","char_li = [c for c in \" abcdefghijklmnopqrstuvwxyz/-'1234567890.\"]\n","word_dict = {n: i for i, n in enumerate(char_li)}\n","number_dict = {i: w for i, w in enumerate(char_li)}"]},{"cell_type":"markdown","metadata":{"id":"n1R_C3d6u3Yf"},"source":["# Train_test split the data"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1670595184894,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"62jmXtAOLdtn","outputId":"06a5e7c6-37a9-4586-85ba-ed10e1ec022c"},"outputs":[{"data":{"text/plain":["100729"]},"execution_count":52,"metadata":{},"output_type":"execute_result"}],"source":["x_train_dem, x_test_dem, y_train_dem, y_test_dem = train_test_split(word, sylla_count, test_size=0.2, random_state=42)\n","len(x_train_dem)"]},{"cell_type":"markdown","metadata":{"id":"cGJ7N7kEs-n2"},"source":["# Embeding, convert to tensor and batching tha data\n"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1670595185488,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"0b_dabEmwN7U","outputId":"bd4fb69b-3ccb-4de5-f369-1cd103392b76"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 8,  1,  9,  ...,  0,  0,  0],\n","        [19,  9, 13,  ...,  0,  0,  0],\n","        [21, 14, 10,  ...,  0,  0,  0],\n","        ...,\n","        [ 1,  4,  1,  ...,  0,  0,  0],\n","        [ 2, 21, 19,  ...,  0,  0,  0],\n","        [23,  5, 19,  ...,  0,  0,  0]])\n","torch.Size([100729])\n"]}],"source":["# Embedding the data into word vector and convert to tensor\n","\n","def convert_to_tensor(x, y, word_dict):\n","    np_x = []\n","\n","    for each_word in x:\n","        vec_each_word = [word_dict[n] for n in each_word] # look up each charactor in each word and convert into the character's index from our word dictionary\n","        np_x.append(vec_each_word)\n","\n","    # Change both list into tensor\n","    tensor_x = torch.LongTensor(np_x)\n","    tensor_y = torch.LongTensor(y)\n","\n","    return tensor_x, tensor_y\n","\n","tensor_x_train_dem, tensor_y_train_dem = convert_to_tensor(x_train_dem, y_train_dem, word_dict)\n","print(tensor_x_train_dem)\n","print(tensor_y_train_dem.size())"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1670595185787,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"v6Ax9mo9phsf","outputId":"debf259f-e894-4a80-dd74-4ff64a002c58"},"outputs":[{"name":"stdout","output_type":"stream","text":["input\n","tensor([[ 8,  5, 18,  7, 15, 20, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [13,  9,  3,  8,  1,  5, 12, 12,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","output\n","tensor([2, 3])\n","\n"]}],"source":["# Implement the dataloader for batching the data when feeding the data to the model\n","data = list(zip(tensor_x_train_dem, tensor_y_train_dem))\n","batch_size = 2\n","shuffle = True\n","\n","loader_dem = DataLoader(data, batch_size=batch_size, shuffle = shuffle)\n","\n","for x_train, y_train in loader_dem:\n","    print('input')\n","    print(x_train)\n","    print('output')\n","    print(y_train)\n","    print()\n","    break"]},{"cell_type":"markdown","metadata":{"id":"9aYcVUs7zPg3"},"source":["# LSTM Model"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670595185787,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"t3l3YreKzUPE"},"outputs":[],"source":["# Declare the parameters for the layers\n","n_hidden = 128\n","n_class = len(word_dict)\n","max_syllabus = 20"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670595185787,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"QzO_YuNKwmz0"},"outputs":[],"source":["# Implement the LSTM model\n","\n","class TextLSTM(nn.Module):\n","    def __init__(self, n_class, n_hidden, max_syllabus):\n","        super(TextLSTM, self).__init__()\n","\n","        # Declare variable\n","        self.n_class = n_class\n","        self.n_hidden = n_hidden\n","        self.max_syllabus = max_syllabus\n","        \n","        # Embedding layer\n","        self.embedd = nn.Embedding(num_embeddings=n_class, embedding_dim=5) # [n_class, 5]\n","        \n","        # LSTM layer\n","        self.lstm = nn.LSTM(input_size=5, hidden_size=n_hidden) # [5, n_hidden]\n","\n","        # Linear layer\n","        self.W = nn.Linear(n_hidden, max_syllabus, bias=True) # [n_hidden, max_syllabus]\n","        \n","        # Softmax layer\n","        # self.probabilities = nn.LogSoftmax() # [n_hidden, max_syllabus]\n","\n","    def forward(self, tensor_train):\n","        tensor_train = tensor_train.transpose(0, 1)\n","        \n","        # Embedding the input\n","        embedded = self.embedd(tensor_train)\n","        \n","        # Pass through the LSTM\n","        model, (_, _) = self.lstm(embedded)\n","        model = model[-1]\n","        \n","        # Pass through the linear layer\n","        model = self.W(model)\n","        \n","        # Softmax layer\n","        # model = self.probabilities(model)\n","        \n","        return model"]},{"cell_type":"markdown","metadata":{"id":"VIqcReYtvIOn"},"source":["# Training process"]},{"cell_type":"code","execution_count":57,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1670595185788,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"0zkS1YS7JKG9"},"outputs":[],"source":["# Init the model, loss, and optimizer\n","model = TextLSTM(n_class, n_hidden, max_syllabus)\n","# criterion = nn.NLLLoss() \n","criterion = nn.CrossEntropyLoss() \n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# The criterion can be changed into CrossEntropyLoss() \n","# to give higher rate of prediction (~95%)\n","# However, you need to deactivate the Softmax layer in the model class\n","# to use this loss and change the learning rate into 0.001"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":1747,"status":"ok","timestamp":1670595187531,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"rTjkdAhlmtM7"},"outputs":[],"source":["# Spliting the train_test dataset and convert them to tensor\n","x_train, x_test, y_train, y_test = train_test_split(word, sylla_count, test_size=0.1, random_state=42)\n","tensor_x_train, tensor_y_train = convert_to_tensor(x_train, y_train, word_dict)\n","\n","# Init the training loader\n","loader = DataLoader(list(zip(tensor_x_train, tensor_y_train)), batch_size = 1024, shuffle = True)\n","\n","# Put the model into the cuda for computatiing purpose on cuda\n","model = model.to(device)"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":320,"status":"ok","timestamp":1670595187848,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"xmTmtfIcHzCB","outputId":"f3d92ccc-0884-4880-a498-65bed17b20ac"},"outputs":[{"data":{"text/plain":["tensor(12)"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["# Check the size of the traing data\n","max(tensor_y_train)"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":160152,"status":"ok","timestamp":1670595347998,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"Rd1CR_klFbNF","outputId":"01bf42d2-4e75-49d9-960e-9426ce3125c9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 0010 cost = 149.519117\n","Epoch: 0020 cost = 149.560303\n","Epoch: 0030 cost = 149.567893\n","Epoch: 0040 cost = 33.668607\n","Epoch: 0050 cost = 26.131243\n","Epoch: 0060 cost = 21.884402\n","Epoch: 0070 cost = 18.665262\n","Epoch: 0080 cost = 16.597061\n","Epoch: 0090 cost = 14.464481\n","Epoch: 0100 cost = 13.051680\n"]}],"source":["# Train the data for the \"epoch = 100\" times\n","for epoch in range(100):\n","    tot_loss = 0 # calculate the total loss of each batch\n","\n","    for x_train, y_train in loader:\n","\n","        # Put the batch onto cuda\n","        x_train, y_train = x_train.to(device), y_train.to(device)\n","        \n","        # Set the optimizer back to 0\n","        optimizer.zero_grad()\n","\n","        # Feed the x_train to the model\n","        output = model(x_train)\n","\n","        # Calculate the loss and backproping\n","        loss = criterion(output, y_train)\n","        loss.backward()\n","    \n","        # Calculate the total loss and optimize\n","        tot_loss += loss.item()\n","        optimizer.step()\n","\n","    # print the total loss\n","    if (epoch + 1) % 10 == 0:\n","        print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.6f}'.format(tot_loss))"]},{"cell_type":"markdown","metadata":{"id":"EOZeIOUkvLLK"},"source":["# Testing the model\n","\n","Feed the model with our test dataset to see the model perfomance"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1670595347999,"user":{"displayName":"Gia-Huy Do","userId":"10885082219265983604"},"user_tz":300},"id":"E3c1ORv200cr","outputId":"64cb6e47-619e-4d9a-dd3e-907937ff6ce4"},"outputs":[{"data":{"text/plain":["tensor([[16,  9, 12,  ...,  0,  0,  0],\n","        [ 7, 15, 15,  ...,  0,  0,  0],\n","        [ 1, 18,  1,  ...,  0,  0,  0],\n","        ...,\n","        [ 1, 21,  4,  ...,  0,  0,  0],\n","        [ 9, 14, 21,  ...,  0,  0,  0],\n","        [16,  1, 15,  ...,  0,  0,  0]], device='cuda:0')"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["# Convert the test dataset to tensor\n","tensor_x_test, tensor_y_test = convert_to_tensor(x_test, y_test, word_dict)\n","\n","# Put the tensors onto cuda\n","tensor_x_test = tensor_x_test.to(device)\n","tensor_y_test = tensor_y_test.to(device)\n","tensor_x_test"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["dinmukhamed                  3 4\n","ratatouille                  4 3\n","rolemodel                    4 3\n","flour                        1 2\n","nutriclean                   4 3\n","sarejevo's                   3 4\n","genuine                      2 3\n","cecelia                      4 3\n","deisher                      2 3\n","fuels                        1 2\n","puig                         2 1\n","fukuoka                      3 4\n","socialite                    4 3\n","baidoan                      2 3\n","joelle                       1 2\n","polyak                       3 2\n","emeralds                     3 2\n","hoene                        1 2\n","lavinia                      4 3\n","coretech                     3 2\n","archaic                      2 3\n","wunderle                     2 3\n","yeagle                       1 2\n","imai                         3 2\n","stoicism                     3 4\n","machetes                     2 3\n","riviera                      3 4\n","miniaturize                  5 4\n","historically                 4 5\n","deline                       2 3\n","gessler                      2 3\n","enabler                      3 4\n","vanliew                      2 3\n","gorazde                      2 3\n","coen                         1 2\n","rearrested                   3 4\n","algemene                     2 3\n","methodically                 4 5\n","professorial                 4 5\n","quenneville                  2 3\n","samuelle                     2 3\n","sedore                       2 3\n","beata                        2 3\n","moredock                     2 3\n","one-on-one                   4 3\n","soldier                      3 2\n","cacciola                     4 3\n","kensler                      2 3\n","chocolates                   3 2\n","quieting                     2 3\n","laverdure                    3 4\n","hotwired                     2 3\n","d'genetta                    3 4\n","obanion                      4 3\n","dievler                      3 2\n","virazole                     4 3\n","nameplates                   3 2\n","colosseum                    3 4\n","buell                        1 2\n","abs                          1 3\n","schiffler                    2 3\n","lieutenant's                 4 3\n","gauthier                     2 3\n","valdes-perez                 3 4\n","blasier's                    2 3\n","suu                          1 3\n","isosceles                    3 4\n","waidelich                    3 2\n","ringuette                    3 2\n","hapke                        1 2\n","corneliuson                  4 5\n","yarmulkes                    2 3\n","fritzsche                    2 1\n","whimsically                  4 3\n","cantone                      2 3\n","iacovelli                    4 5\n","papale                       2 3\n","textual                      2 3\n","ciocca                       3 2\n","c.d.s                        1 2\n","chrzanowski                  3 4\n","dionysius                    4 5\n","magnolia                     4 3\n","undeniable                   4 5\n","stablest                     2 3\n","airedales                    3 2\n","bruegge                      1 2\n","sikhism                      3 2\n","nvryan                       2 3\n","oprah's                      3 2\n","mhoon                        2 1\n","greear                       1 2\n","verde                        1 2\n","beatified                    3 4\n","arsehole                     3 2\n","cian                         2 1\n","saint-saens                  3 2\n","mazzone                      2 3\n","texas'                       2 3\n","baffling                     2 3\n","beautician                   4 3\n","mosler                       2 3\n","mcinnes                      2 3\n","xiaoyun                      3 2\n","therese                      1 2\n","entringer                    3 4\n","parochialism                 5 6\n","brouillette                  3 2\n","brachia                      2 3\n","ultranationalist's           7 6\n","weidler                      2 3\n","coalescence                  3 4\n","valencia                     3 4\n","noncorporate                 4 3\n","viramune                     3 4\n","yessuey                      2 3\n","kubes                        1 2\n","passe                        1 2\n","linear                       2 3\n","tomasine                     3 4\n","noticeably                   5 4\n","uhle                         1 2\n","ziesmer                      2 3\n","av                           1 2\n","usameribancs                 5 6\n","ksiazek                      3 2\n","dr                           2 1\n","ididerod                     3 4\n","bulkeley                     2 3\n","sovereign                    3 2\n","driest                       1 2\n","coplen                       2 3\n","suv                          1 3\n","dsouza                       2 3\n","afroamericans                5 6\n","scheidler                    2 3\n","theriault                    2 3\n","harare                       2 3\n","truex                        1 2\n","deluise                      2 3\n","non-interest                 4 3\n","d'amore                      2 4\n","underneath                   4 3\n","theorem                      3 2\n","dunmire                      2 3\n","mahe                         1 2\n","ninety's                     3 2\n","encroachment                 4 3\n","jefferies's                  4 3\n","zimbabwe                     2 3\n","ciccarone                    4 3\n","juliet                       2 3\n","weyerhaeuser                 4 3\n","saccone                      2 3\n","persuasion                   4 3\n","beach's                      1 2\n","dandelion                    3 4\n","oleaster                     3 4\n","q.                           3 1\n","viceroy                      3 2\n","recore                       2 3\n","baldassare                   3 4\n","parenthetically              5 6\n","espionage                    3 4\n","imagery                      4 3\n","preempted                    2 3\n","overrepresented              5 6\n","wiest                        1 2\n","cnn.com                      2 5\n","cacld                        1 2\n","belgium's                    3 2\n","blauer                       2 1\n","rodeheaver                   3 4\n","kisling                      2 3\n","hsiung                       1 2\n","lionberger                   3 4\n","syncope                      2 3\n","quieted                      2 3\n","misjudges                    2 3\n","tempe                        1 2\n","reust                        2 1\n","corbusier                    4 3\n","tocqueville's                3 2\n","giguere                      2 3\n","hydropower                   4 3\n","monologues                   4 3\n","shh                          3 0\n","treichler                    2 3\n","digiuseppe                   3 4\n","kcop                         1 2\n","hazelett                     2 3\n","weinzierl                    3 2\n","ionarde                      3 4\n","canipe                       2 3\n","gorospe                      2 3\n","villarreal                   4 3\n","nitzsche                     2 1\n","pm                           3 2\n","recovery                     4 3\n","yolande                      3 2\n","counterespionage             5 6\n","self-interest                4 3\n","colonialism                  5 6\n","navarre                      3 2\n","dimichele                    3 4\n","carryover                    4 3\n","barentine                    3 4\n","langone                      2 3\n","liebling                     2 3\n","traditionalists              5 4\n","tragically                   4 3\n","grunewald                    2 3\n","bonfires                     2 3\n","brandeberry                  4 3\n","mccaughan                    3 2\n","ludke                        1 2\n","wired                        1 2\n","lamarche                     2 3\n","opinion                      4 3\n","satires                      2 3\n","ancients                     3 2\n","reinsel                      3 2\n","intuitive                    3 4\n","perine                       2 3\n","monforte                     2 3\n","andrzejewski                 5 4\n","hemophiliacs                 4 5\n","pursuant                     2 3\n","photoop                      2 3\n","dulcea                       2 3\n","jesse                        1 2\n","samuels                      2 3\n","guisewite                    3 2\n","giampaolo                    4 3\n","biehle                       1 2\n","cineplex's                   3 4\n","silicone                     4 3\n","pelagians                    3 4\n","hideout                      3 2\n","telugu                       2 3\n","koninklijke                  3 4\n","sias                         2 1\n","mevarachs                    3 4\n","ricaurte                     2 3\n","galatea                      3 4\n","linearly                     3 4\n","drouin                       2 1\n","hustlers                     2 3\n","counterrevolutionary         7 8\n","allemand                     2 3\n","deinstitutionalization       8 9\n","cemetery                     3 4\n","wiitala                      4 3\n","hces                         1 4\n","andrzej                      3 2\n","everyone's                   4 3\n","dessauer                     3 2\n","beryllium                    3 4\n","prof.                        2 1\n","sayed                        1 2\n","quietness                    2 3\n","biodegradable                5 6\n","missildine                   3 4\n","zairian                      3 4\n","statuesque                   2 3\n","evacuees                     3 4\n","nuovo                        3 2\n","issuable                     3 4\n","barricaded                   3 4\n","raffaelli                    3 4\n","iovine                       3 4\n","yeung                        2 1\n","duana                        2 3\n","tuinstra                     2 3\n","oncale                       2 3\n","viramunes                    3 4\n","mealo                        2 3\n","josephine's                  2 3\n","quagmire                     2 3\n","gamsakhurdia                 4 5\n","kennemore                    3 2\n","chrzan                       1 2\n","azalea                       4 3\n","bonenfant                    3 2\n","calabrese                    3 4\n","awfully                      3 2\n","yarmulke                     2 3\n","roseboro                     4 3\n","sonneborn                    2 3\n","pokemon                      2 3\n","hemiplegia                   4 5\n","gruel                        1 2\n","savior's                     3 2\n","revuelta                     4 3\n","sioux                        2 1\n","orleanians                   4 5\n","dildine                      2 3\n","ulaanbaatar                  5 4\n","disequilibrium               5 6\n","kyoshi                       2 3\n","hyotan                       3 2\n","veroa                        2 3\n","peaudouce                    3 2\n","w                            1 3\n","fatiguing                    4 3\n","aldape                       2 3\n","schoeffler                   2 3\n","visually                     4 3\n","valente                      2 3\n","versace                      2 3\n","jesuits                      2 3\n","icebox                       3 2\n","latanze                      2 3\n","skowhegan                    2 3\n","ndau                         1 2\n","hisao                        2 3\n","rijn                         1 2\n","half-hour                    2 3\n","hallbauer                    3 2\n","pyrenees'                    2 3\n","joscelyne                    2 3\n","gabrys                       2 3\n","jean-baptiste                4 3\n","irremediable                 5 6\n","alienating                   4 5\n","doan's                       2 1\n","congolese                    2 3\n","tolkien                      2 3\n","keasler                      3 2\n","sgt                          3 2\n","hossler                      2 3\n","morgante                     2 3\n","anxiously                    4 3\n","la-carre                     2 3\n","togetherness                 3 4\n","guinier                      3 2\n","hemophilia                   4 5\n","boghosian                    4 3\n","miscreant                    2 3\n","wiseley                      2 3\n","belluomini                   5 4\n","pigeon                       3 2\n","santa-fe                     2 3\n","dirienzo                     4 3\n","dobler                       2 3\n","lavecchia                    3 4\n","treml                        1 2\n","naturedly                    4 3\n","extraterritoriality          7 9\n","rioux                        2 1\n","curle                        1 2\n","lyonnais's                   3 4\n","toppling                     2 3\n","scarpone                     2 3\n","tingler                      2 3\n","redlinger                    3 4\n","powerpcs'                    2 4\n","x's                          1 2\n","petrone                      2 3\n","dna                          1 3\n","hour                         1 2\n","huang                        2 1\n","garavaglia                   4 5\n","usmc                         2 4\n","bay-area                     3 4\n","incheon                      3 2\n","stuarts                      1 2\n","sciuto                       2 3\n","electronically               5 6\n","st-martin                    2 3\n","initialed                    4 3\n","permeable                    3 4\n","quiescent                    2 3\n","unrealistic                  5 4\n","freda                        2 1\n","ptovsky                      2 3\n","cdebaca                      3 4\n","lahue                        1 2\n","holyoak                      2 3\n","resende                      2 3\n","findling                     2 3\n","wrangler                     2 3\n","michener's                   3 2\n","orpheus                      2 3\n","jeopardized                  4 3\n","waldholtz's                  2 3\n","albanese                     3 4\n","anatole                      4 3\n","loewe                        1 2\n","costeira                     3 4\n","galeb                        1 2\n","vossler                      2 3\n","kanouse                      2 4\n","underdevelop                 4 5\n","minjares                     2 3\n","lyrically                    4 3\n","luncheonettes                4 3\n","urls                         1 3\n","presler                      2 3\n","whomsoever                   3 4\n","well-being                   2 3\n","rolemodels                   4 3\n","chameleon                    3 4\n","divinely                     4 3\n","korenek                      2 3\n","monte                        1 2\n","ayende                       2 3\n","carmean                      2 3\n","stai                         1 2\n","fm                           3 2\n","opera                        3 2\n","thoroughbred                 2 3\n","berthiaume                   3 4\n","scoured                      1 2\n","quinoa                       2 3\n","munich's                     3 2\n","kuenzi                       2 3\n","edgewise                     3 2\n","mcalinden                    4 3\n","vidalia                      4 3\n","palau's                      2 3\n","constantinides               4 5\n","horseflesh                   3 2\n","satiety                      3 4\n","montrealers                  3 4\n","waleson                      3 2\n","mangiaracina                 6 5\n","kopischke                    2 3\n","cereal                       2 3\n","meineke                      2 3\n","scalia                       2 3\n","cortelyou                    4 3\n","neoplasm                     3 4\n","delbene                      2 3\n","scialdone                    2 3\n","deemphasizing                4 5\n","benevides                    3 4\n","piety                        2 3\n","lucrezia                     4 3\n","vetoing                      2 3\n","zenia                        2 3\n","ognibene                     3 4\n","rippling                     2 3\n","anemone                      2 3\n","bene                         1 2\n","requiring                    3 4\n","campfire                     2 3\n","principally                  4 3\n","preamble                     2 3\n","koichi                       2 3\n","asheboro                     4 3\n","megadeals                    4 3\n","stier                        1 2\n","cruikshank                   2 3\n","shiite                       1 2\n","coinciding                   3 4\n","osteoarthritis               5 6\n","kroening                     2 3\n","rainger                      2 3\n","middling                     2 3\n","stiers                       1 2\n","cartesian                    4 3\n","twinkly                      2 3\n","italian                      4 3\n","sophomore                    3 2\n","mangine                      2 3\n","prescience                   2 3\n","radioed                      2 3\n","interest                     3 2\n","tiaacref                     2 3\n","ellesmere                    3 2\n","oui                          2 1\n","cutesy                       3 2\n","chuang                       2 1\n","facelift                     3 2\n","heroin                       2 3\n","ostia                        2 3\n","montgomery's                 4 3\n","buechler                     2 3\n","rodewald                     2 3\n","ganatieuganauf               6 5\n","coexisted                    3 4\n","frashier                     3 2\n","underdevelopment             5 6\n","blakeslee                    3 2\n","oceanic                      3 4\n","hineline                     2 3\n","kokate                       2 3\n","supergiant                   3 4\n","jaime's                      1 2\n","s.'s                         1 2\n","gatzke                       2 1\n","magnesia                     4 3\n","styer                        1 2\n","ghettoize                    2 3\n","firehouses                   3 4\n","vidales                      2 3\n","minoan                       2 3\n","autumn's                     3 2\n","abreu                        3 2\n","likhyani                     4 3\n","cea                          1 3\n","denarii                      4 3\n","leopards                     3 2\n","idealized                    3 4\n","euthanasia's                 5 4\n","mri                          1 3\n","gloucester                   3 2\n","cacioppo                     4 3\n","joann                        1 2\n","heberle                      2 3\n","mckeown                      2 3\n","peculiar                     4 3\n","mcgoey                       2 3\n","testes                       1 2\n","manzanares                   3 4\n","wermiel                      2 3\n","montien                      2 3\n","adventuresome                5 4\n","wisniewski                   3 4\n","photovoltaic                 4 5\n","przybyl                      2 3\n","catherines                   3 2\n","proteges                     2 3\n","codebreaker                  4 3\n","aegean                       2 3\n","paredes                      2 3\n","ianthe                       2 3\n","martialed                    3 2\n","pourciau                     2 3\n","da's                         1 2\n","aguinaga                     4 5\n","superx                       2 3\n","yorio                        3 2\n","vaapenfabrikk                5 4\n","villagomez                   3 4\n","naive                        1 2\n","aganbegyan                   5 4\n","grua                         1 2\n","ames's                       3 2\n","rainier                      3 2\n","acquirer's                   3 4\n","mirelez                      2 3\n","linguist                     3 2\n","nobler                       3 2\n","reichler                     3 2\n","materiel                     3 4\n","korean's                     3 2\n","pierre                       1 2\n","deremer                      2 3\n","mormonism                    4 3\n","kibler                       3 2\n","neumeister                   4 3\n","lorean                       2 3\n","attebury                     4 3\n","myanmar's                    3 2\n","misiaszek                    3 4\n","guinier's                    3 2\n","promiscuity                  4 5\n","cianciolo                    4 3\n","muolo                        3 2\n","yuletide                     3 2\n","cit                          1 3\n","vorhauer                     3 2\n","emotionally                  5 4\n","mangone                      2 3\n","business                     3 2\n","rieth                        1 2\n","overreacts                   3 4\n","acetaminophen                5 6\n","parthenia                    3 4\n","agricole                     4 3\n","opinionated                  6 5\n","carnine                      2 3\n","ethereal                     3 4\n","reimposed                    2 3\n","dinehart                     3 2\n","dlugosz                      2 3\n","salles                       1 2\n","lenke                        1 2\n","loise                        1 2\n","haseley                      2 3\n","calcote                      2 3\n","ufo                          2 3\n","bustier                      3 2\n","grauel                       1 2\n","valkyrie                     3 4\n","mcalexander                  4 5\n","lafler                       2 3\n","renate                       2 3\n","prenuptial                   4 3\n","hyaluronic                   4 5\n","appreciated                  4 5\n","affiliate's                  3 4\n","huachuca                     4 3\n","lafosse                      3 2\n","kuomintang's                 4 3\n","cassia                       2 3\n","ths                          2 0\n","granese                      3 2\n","goering                      2 3\n","yehle                        1 2\n","cuello                       2 3\n","spraying                     1 2\n","byu                          1 3\n","Accuracy:  95.1953621346887 %\n"]}],"source":["# Test the model\n","predict = model(tensor_x_test).data\n","predict_1 = [int(np.argmax(x)) for i, x in enumerate(predict.cpu())]\n","\n","# Count the number of correct prediction\n","count = 0\n","for i in range(len(tensor_y_test)):\n","    if predict_1[i] - int(tensor_y_test[i]) == 0:\n","        count += 1\n","    \n","    else:\n","        print(x_test[i], predict_1[i], int(tensor_y_test[i])) # printout incorrect prediction\n","\n","# Print the result\n","print(\"Accuracy: \", count/len(tensor_y_test)*100, \"%\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"NLP","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.15 (default, Nov 24 2022, 09:04:07) \n[Clang 14.0.6 ]"},"vscode":{"interpreter":{"hash":"f48d9550db41daf67a6ff456c92b13d24bd6d6b8fa468b40929ebf6b89e0fcf3"}}},"nbformat":4,"nbformat_minor":0}
